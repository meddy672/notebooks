{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe36d40-c17d-4af5-ad5d-4fea3b878161",
   "metadata": {},
   "source": [
    "# LangChain Examples\n",
    "LangChain is a framework for developing applications powered by Large Language Models (LLMs). It enables applications that:\n",
    "- Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)\n",
    "- Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)\n",
    "\n",
    "## Lesson Examples\n",
    "- Prompt Templates\n",
    "- Prompt Chains\n",
    "- Memory\n",
    "- Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15d3c8-4498-4ed3-bcae-c4ae808e31a9",
   "metadata": {},
   "source": [
    "### Setup\n",
    "ChatGPT is used as the LLM for these examples, but supports a ton of LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "29f3c32f-5f52-415c-a5ef-b2083f1f2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffbbaf1-1066-4584-b8d1-aea5922b9b42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Prompt Templates\n",
    "With LangChain you can easily create templates for your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "73ecae06-607d-40fa-92b0-f9b05e2173dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "template = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# create prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40364c47-fcc9-4d8a-993a-7f421a78268a",
   "metadata": {},
   "source": [
    "##### Create Template Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f51b5e57-0beb-4895-93a2-5ee2433e610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "抱歉，這次購買電視的體驗讓我非常失望。\\\n",
    "首先，產品的品質並不符合我的期望，\\\n",
    "屏幕有明顯的問題，影響觀看效果。其次，\\\n",
    "客戶服務也十分不滿意，解決問題的速度很慢，\\\n",
    "而且態度不夠友好。總的來說，這次購買讓我感到非常不滿，\\\n",
    "我不會推薦這個品牌給任何人。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7ab78-2139-48b8-b8a5-45ec0ba6de1f",
   "metadata": {},
   "source": [
    "##### Initialize template varibales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d3c9d3df-92b1-4091-8f5d-1802b68f57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569577c-f348-4544-881f-e39abae547ba",
   "metadata": {},
   "source": [
    "##### Send Request & Print Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "75c11b73-3c57-4ecf-9e67-9a20ede7095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but my experience with purchasing this TV has been very disappointing. First of all, the quality of the product did not meet my expectations, as the screen has obvious issues that affect the viewing experience. Additionally, I was very dissatisfied with the customer service - the problem-solving process was slow and the attitude was not friendly enough. Overall, this purchase has left me feeling very unsatisfied, and I would not recommend this brand to anyone.\n"
     ]
    }
   ],
   "source": [
    "customer_response = chat.invoke(customer_messages)\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9b3fa-13df-4c2b-882e-4278ab248a21",
   "metadata": {},
   "source": [
    "### Prompt Chains\n",
    "At times we want to take the response from one prompt and use it in another. We can acomplish this with **SequentialChain and LLMChain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4701d3b5-382e-4d4e-a020-7a2f211f0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "product = \"Queen Size Sheet Set\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed8172-fb02-4d80-816b-a4ef86f1ff31",
   "metadata": {},
   "source": [
    "##### Create first prompt in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "524883bf-4d50-4a09-8689-befa782bee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58efa4d-cb4d-48fd-8ba3-8656d4fe845d",
   "metadata": {},
   "source": [
    "##### Create second prompt in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "02edd5f3-7027-4dfc-94d7-151a3f33dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 word description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da336042-24d0-4ea1-8b1e-02ff5ce01835",
   "metadata": {},
   "source": [
    "##### Link the chains together with a SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3785c9c4-2c1b-45de-a746-cf8bc2d30089",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca321602-f5d1-4189-ad65-f29d4478f1f9",
   "metadata": {},
   "source": [
    "##### Send the request & print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "799cc33f-0d02-490b-b996-8a2dd6cb2e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRegal Linens\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRegal Linens provides luxurious and high-quality bedding and linens to elevate your home decor and create a stylish ambiance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Queen Size Sheet Set',\n",
       " 'output': 'Regal Linens provides luxurious and high-quality bedding and linens to elevate your home decor and create a stylish ambiance.'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943236e1-b3ab-42a5-9c25-4e3b031bc2ba",
   "metadata": {},
   "source": [
    "### Memory\n",
    "LLMs are stateless. This means they do not store the conversation history. LangChain provides an API that you can use to store conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9f0a86f6-9595-4fac-a500-41399509f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3235115-be26-417f-a18d-36184c70fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f1477ad7-15e5-4562-a297-534717a53064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "14ee41a6-2a24-4f17-84b9-c4bcc30452e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew. Is there anything else you would like to know, Andrew?'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fbbaa-c964-4950-9f9d-6addf4c32681",
   "metadata": {},
   "source": [
    "### Tools\n",
    "LangChain is equipped with tons of tools that you can use to integrate within your LLM. [See More](https://python.langchain.com/docs/integrations/tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e46273-4339-4fec-93b2-81479c0aa3fa",
   "metadata": {},
   "source": [
    "##### Example Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "063f4bde-f7eb-4c78-9a21-8b5737a7596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Q7251:\n",
      "Label: Alan Turing\n",
      "Description: English computer scientist (1912–1954)\n",
      "Aliases: Alan M. Turing, Alan Mathieson Turing, Turing, Alan Mathison Turing\n",
      "instance of: human\n",
      "country of citizenship: United Kingdom\n",
      "occupation: computer scientist, mathematician, university teacher, cryptographer, logician, statistician, marathon runner, artificial intelligence researcher\n",
      "sex or gender: male\n",
      "date of birth: 1912-06-23\n",
      "date of death: 1954-06-07\n",
      "sport: athletics\n",
      "place of birth: Maida Vale, Warrington Lodge\n",
      "educated at: King's College, Princeton University, Sherborne School, Hazlehurst Community Primary School\n",
      "employer: Victoria University of Manchester, Government Communications Headquarters, University of Cambridge, National Physical Laboratory\n",
      "place of death: Wilmslow\n",
      "field of work: cryptanalysis, computer science, mathematics, logic, cryptography\n",
      "cause of death: cyanide poisoning\n",
      "notable work: On Computable Numbers, with an Application to the Entscheidungsproblem, Computing Machinery and Intelligence, Intelligent Machinery, halting problem, Turing machine, Turing test, Turing completeness, Church-Turing thesis, universal Turing machine, Symmetric Turing machine, non-deterministic Turing machine, Bombe, probabilistic Turing machine, Turing degree\n",
      "religion or worldview: atheism\n",
      "mother: Ethel Sara Stoney\n",
      "father: Julius Mathison Turing\n",
      "doctoral student: Robin Gandy, Beatrice Helen Worsley\n",
      "student: Robin Gandy\n",
      "\n",
      "Result Q28846012:\n",
      "Label: Alan Turing\n",
      "Description: fictional analogon of Alan Turing (1912-1954)\n",
      "Aliases: Alan Mathison Turing\n",
      "instance of: fictional human\n",
      "sex or gender: male\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.wikidata.tool import WikidataAPIWrapper, WikidataQueryRun\n",
    "\n",
    "wikidata = WikidataQueryRun(api_wrapper=WikidataAPIWrapper())\n",
    "\n",
    "print(wikidata.run(\"Alan Turing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285196ff-67bb-4614-8126-fccaa8f971ad",
   "metadata": {},
   "source": [
    "##### Example Youtube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cf5c37b2-3b5b-4db6-be39-70d986a1eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=PgGKhsWhUu8&pp=ygUMbGV4IGZyaWVkbWFu', 'https://www.youtube.com/watch?v=zgbFJiGHVAc&pp=ygUMbGV4IGZyaWVkbWFu']\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import YouTubeSearchTool\n",
    "\n",
    "tool = YouTubeSearchTool()\n",
    "\n",
    "tool.run(\"lex friedman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80053f00-4cf1-42e4-86da-f183bb215081",
   "metadata": {},
   "source": [
    "##### Example PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cb5a8caf-47a2-4f80-bbd0-3836f55ac188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-02-19\\nTitle: Investigating the potential causal association between consumption of green tea and risk of lung cancer: a study utilizing Mendelian randomization.\\nCopyright Information: Copyright © 2024 Lu, Lin, Jiang, Gao, Shen, Yang, Lin and Kang.\\nSummary::\\nBACKGROUND: Lung cancer is the most common global cancer in terms of incidence and mortality. Its main driver is tobacco smoking. The identification of modifiable risk factors isa public health priority. Green tea consumption has been examined in epidemiological studies, with inconsistent findings. Thus, we aimed to apply Mendelian randomization to clarify any causal link between green tea consumption and the risk of lung cancer.\\nMETHODS: We utilized a two-sample Mendelian randomization (MR) approach. Genetic variants served as instrumental variables. The goal was to explore a causal link between green tea consumption and different lung cancer types. Green tea consumption data was sourced from the UK Biobank dataset, and the genetic association data for various types of lung cancer were sourced from multiple databases. Our analysis included primary inverse-variance weighted (IVW) analyses and various sensitivity test.\\nRESULTS: No significant associations were found between green tea intake and any lung cancer subtypes, including non-small cell lung cancer (adenocarcinoma and squamous cell carcinoma) and small cell lung cancer. These findings were consistent when applying multiple Mendelian randomization methods.\\nCONCLUSION: Green tea does not appear to offer protective benefits against lung cancer at a population level. However, lung cancer's complex etiology and green tea's potential health benefitssuggest more research is needed. Further studies should include diverse populations, improved exposure measurements and randomized controlled trials, are warranted.\\n\\nPublished: 2024-02-22\\nTitle: TP53 mitigates cisplatin resistance in non-small cell lung cancer by mediating the effects of resistant cell\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.pubmed.tool import PubmedQueryRun\n",
    "\n",
    "tool = PubmedQueryRun()\n",
    "\n",
    "tool.invoke(\"What causes lung cancer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999a8ce-2a24-4467-802b-400c97492f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
