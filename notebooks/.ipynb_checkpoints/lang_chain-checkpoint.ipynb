{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe36d40-c17d-4af5-ad5d-4fea3b878161",
   "metadata": {},
   "source": [
    "# LangChain Examples\n",
    "LangChain is a framework for developing applications powered by Large Language Models (LLMs). It enables applications that:\n",
    "- Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)\n",
    "- Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)\n",
    "\n",
    "## Lesson Examples\n",
    "- Prompt Templates\n",
    "- Prompt Chains\n",
    "- Memory\n",
    "- Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15d3c8-4498-4ed3-bcae-c4ae808e31a9",
   "metadata": {},
   "source": [
    "### Setup\n",
    "ChatGPT is used as the LLM for these examples, but supports a ton of LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "29f3c32f-5f52-415c-a5ef-b2083f1f2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffbbaf1-1066-4584-b8d1-aea5922b9b42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Prompt Templates\n",
    "With LangChain you can easily create templates for your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73ecae06-607d-40fa-92b0-f9b05e2173dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "template = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# create prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40364c47-fcc9-4d8a-993a-7f421a78268a",
   "metadata": {},
   "source": [
    "##### Create Template Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f51b5e57-0beb-4895-93a2-5ee2433e610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "抱歉，這次購買電視的體驗讓我非常失望。\\\n",
    "首先，產品的品質並不符合我的期望，\\\n",
    "屏幕有明顯的問題，影響觀看效果。其次，\\\n",
    "客戶服務也十分不滿意，解決問題的速度很慢，\\\n",
    "而且態度不夠友好。總的來說，這次購買讓我感到非常不滿，\\\n",
    "我不會推薦這個品牌給任何人。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7ab78-2139-48b8-b8a5-45ec0ba6de1f",
   "metadata": {},
   "source": [
    "##### Initialize template varibales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3c9d3df-92b1-4091-8f5d-1802b68f57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569577c-f348-4544-881f-e39abae547ba",
   "metadata": {},
   "source": [
    "##### Send Request & Print Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c11b73-3c57-4ecf-9e67-9a20ede7095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_response = chat.invoke(customer_messages)\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9b3fa-13df-4c2b-882e-4278ab248a21",
   "metadata": {},
   "source": [
    "### Prompt Chains\n",
    "At times we want to take the response from one prompt and use it in another. We can acomplish this with **SequentialChain and LLMChain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4701d3b5-382e-4d4e-a020-7a2f211f0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "product = \"Queen Size Sheet Set\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed8172-fb02-4d80-816b-a4ef86f1ff31",
   "metadata": {},
   "source": [
    "##### Create first prompt in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "524883bf-4d50-4a09-8689-befa782bee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58efa4d-cb4d-48fd-8ba3-8656d4fe845d",
   "metadata": {},
   "source": [
    "##### Create second prompt in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02edd5f3-7027-4dfc-94d7-151a3f33dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 word description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da336042-24d0-4ea1-8b1e-02ff5ce01835",
   "metadata": {},
   "source": [
    "##### Link the chains together with a SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3785c9c4-2c1b-45de-a746-cf8bc2d30089",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca321602-f5d1-4189-ad65-f29d4478f1f9",
   "metadata": {},
   "source": [
    "##### Send the request & print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cc33f-0d02-490b-b996-8a2dd6cb2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943236e1-b3ab-42a5-9c25-4e3b031bc2ba",
   "metadata": {},
   "source": [
    "### Memory\n",
    "LLMs are stateless. This means they do not store the conversation history. LangChain provides an API that you can use to store conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f0a86f6-9595-4fac-a500-41399509f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3235115-be26-417f-a18d-36184c70fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1477ad7-15e5-4562-a297-534717a53064",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee41a6-2a24-4f17-84b9-c4bcc30452e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fbbaa-c964-4950-9f9d-6addf4c32681",
   "metadata": {},
   "source": [
    "### Tools\n",
    "LangChain is equipped with tons of tools that you can use to integrate within your LLM. [See More](https://python.langchain.com/docs/integrations/tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e46273-4339-4fec-93b2-81479c0aa3fa",
   "metadata": {},
   "source": [
    "##### Example Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f4bde-f7eb-4c78-9a21-8b5737a7596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.wikidata.tool import WikidataAPIWrapper, WikidataQueryRun\n",
    "\n",
    "wikidata = WikidataQueryRun(api_wrapper=WikidataAPIWrapper())\n",
    "\n",
    "print(wikidata.run(\"Alan Turing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285196ff-67bb-4614-8126-fccaa8f971ad",
   "metadata": {},
   "source": [
    "##### Example Youtube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c37b2-3b5b-4db6-be39-70d986a1eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import YouTubeSearchTool\n",
    "\n",
    "tool = YouTubeSearchTool()\n",
    "\n",
    "tool.run(\"lex friedman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80053f00-4cf1-42e4-86da-f183bb215081",
   "metadata": {},
   "source": [
    "##### Example PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a8caf-47a2-4f80-bbd0-3836f55ac188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pubmed.tool import PubmedQueryRun\n",
    "\n",
    "tool = PubmedQueryRun()\n",
    "\n",
    "tool.invoke(\"What causes lung cancer?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
